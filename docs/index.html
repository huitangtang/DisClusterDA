<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!--
  <script src="./resources/jsapi" type="text/javascript"></script>
  <script type="text/javascript" async>google.load("jquery", "1.3.2");</script>
 -->
    <style type="text/css">
        @font-face {
            font-family: 'Avenir Book';
            src: url("./fonts/Avenir_Book.ttf"); /* File to be stored at your site */
        }
    body {
    font-family: "Avenir Book", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:14px;
    margin-left: auto;
    margin-right: auto;
    width: 900px;
  }
  h1 {
    font-weight:300;
  }
  h2 {
    font-weight:300;
  }

  p {
    font-weight:300;
    line-height: 1.4;
  }

  code {
    font-size: 0.8rem;
    margin: 0 0.2rem;
    padding: 0.5rem 0.8rem;
    white-space: nowrap;
    background: #efefef;
    border: 1px solid #d3d3d3;
    color: #000000;
    border-radius: 3px;
  }

  pre > code {
    display: block;
    white-space: pre;
    line-height: 1.5;
    padding: 0;
    margin: 0;
  }

  pre.prettyprint > code {
    border: none;
  }


  .container {
        display: flex;
        align-items: center;
        justify-content: center
  }
  .image {
        flex-basis: 40%
  }
  .text {
        padding-left: 20px;
        padding-right: 20px;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;

  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>
	<title>Unsupervised domain adaptation via distilled discriminative clustering</title>
</head>

<body>
<br>
<span style="font-size:36px">
    <div style="text-align: center;">
        Unsupervised domain adaptation via distilled discriminative clustering
    </div>
</span>
<br>
<br>
<br>
<table align="center" width="700px">
    <tr>
        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:16px"><a href="https://huitangtang.github.io/">Hui Tang</a><sup>1</sup></span>
            </div>
        </td>
      
        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:16px"><a href="https://scholar.google.com/citations?user=o_DllmIAAAAJ">Yaowei Wang</a><sup>2</sup></span>
            </div>
        </td>
        
        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:16px">
                    <a href="http://kuijia.site/">Kui Jia</a>
<!--                    <sup><img class="round" style="width:20px" src="./resources/corresponding_fig.png">3</sup>-->
                    <sup>&#9993, 1</sup>
                </span>
            </div>
        </td>
    </tr>
</table>

<br>
	
<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="300px">
            <center>
                <span style="font-size:16px">South China University of Technology<sup>1</sup></span>
            </center>
        </td>
        <td align="center" width="300px">
            <center>
                <span style="font-size:16px">Pengcheng Laboratory<sup>2</sup></span>
            </center>
        </td>
    </tr>
    </tbody>
</table>


<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="300px">
            <center>
                <span style="font-size:16px"><sup>&#9993</sup>Corresponding author</span>
            </center>
        </td>
    </tr>
    </tbody>
</table>

<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:20px">
                    Code
                    <a href="https://github.com/huitangtang/DisClusterDA">[GitHub]</a>
                </span>
            </div>
        </td>

        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:20px">
                    Paper
                    <a href="https://arxiv.org/pdf/2302.11984">[arXiv]</a>
                </span>
            </div>
        </td>

        <td align="center" width="200px">
            <center>
                <span style="font-size:20px">
                    Cite <a href="resources/cite.txt">[BibTeX]</a>
                </span>
            </center>
        </td>
    </tr>
    </tbody>
</table>
<br>
<hr>

<div style="text-align: center;">
    <h2>Teaser</h2>
</div>

<p style="text-align:justify; text-justify:inter-ideograph;">
<table>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/DisClusterDA.png" width="900px">
            </div>
        </td>
    </tr>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
              Motivated by the fundamental assumption for domain adaptability, we re-cast the domain adaptation problem as discriminative clustering of target data, 
              given strong privileged information provided by the closely related, labeled source data. 
              Technically, we use clustering objectives based on a robust variant of entropy minimization that adaptively filters target data, 
              a soft Fisher-like criterion, and additionally the cluster ordering via centroid classification. 
              To distill discriminative source information for target clustering, we propose to jointly train the network using parallel, supervised learning objectives over labeled source data.
            </p>
        </td>
    </tr>
</table>


<br>
<hr>
<div style="text-align: center;">
    <h2>Abstract</h2>
</div>

<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
              Unsupervised domain adaptation addresses the problem of classifying data in an unlabeled target domain, 
              given labeled source domain data that share a common label space but follow a different distribution. 
              Most of the recent methods take the approach of explicitly aligning feature distributions between the two domains. 
              Differently, motivated by the fundamental assumption for domain adaptability, 
              we re-cast the domain adaptation problem as discriminative clustering of target data, 
              given strong privileged information provided by the closely related, labeled source data. 
              Technically, we use clustering objectives based on a robust variant of entropy minimization that adaptively filters target data, 
              a soft Fisher-like criterion, and additionally the cluster ordering via centroid classification. 
              To distill discriminative source information for target clustering, we propose to jointly train the network using parallel, supervised learning objectives over labeled source data. 
              We term our method of distilled discriminative clustering for domain adaptation as DisClusterDA. 
              We also give geometric intuition that illustrates how constituent objectives of DisClusterDA help learn class-wisely pure, compact feature distributions. 
              We conduct careful ablation studies and extensive experiments on five popular benchmark datasets, including a multi-source domain adaptation one. 
              Based on commonly used backbone networks, DisClusterDA outperforms existing methods on these benchmarks. 
              It is also interesting to observe that in our DisClusterDA framework, adding an additional loss term that 
              explicitly learns to align class-level feature distributions across domains does harm to the adaptation performance, 
              though more careful studies in different algorithmic frameworks are to be conducted.
            </p>
        </td>
    </tr>
</table>

<!-- This is the begining of next edition!!!
<br>
<hr>
<div style="text-align: center;">
    <h2>Background & Motivation</h2>
</div>

<table>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/UDA.png" width="600px">
            </div>
        </td>
    </tr>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		The success of deep learning relies on a large amount of training data. 
		However, collecting and annotating data for all domains and tasks is extremely expensive and time-consuming. 
		We can utilize data from a label-rich source domain to solve the task on a label-scarce target domain. 
		But there is a distribution discrepancy between the source and target data. 
		So the model trained on source data cannot be readily applied to target data. 
		How to address this issue? Unsupervised domain adaptation (UDA)!
            </p>
        </td>
    </tr>
    <br>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/strategy.png" width="600px">
            </div>
        </td>
    </tr>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		(a) Illustration of the assumption of structural domain similarity, including two concepts: domain-wise discrimination and class-wise closeness. 
		The orange line denotes the classifier trained on the labeled source data and the green	one denotes the classifier trained on the labeled target data, i.e. the oracle target classifier. 
		(b) Illustration of damaging intrinsic structures of data discrimination on the target domain by the existing transferring strategy. 
		The dashed line denotes the source classifier adapting to the damaged discrimination of target data, which has a sub-optimal generalization. 
		(c) Illustration of our proposed uncovering strategy. Discriminative target clustering with structural source regularization uncovers intrinsic target discrimination. 
		<br>
		<br>
		Mainstream UDA methods take the transferring strategy of learning aligned features across domains, 
		which has a potential risk of damaging the intrinsic discrimination of target data, resulting in a sub-optimal generalization. 
		Based on our assumed structural domain similarity, we directly uncover the intrinsic target discrimination via discriminative clustering of target data 
		and constrain the clustering solutions using structural source regularization, leading to an adapted classifier closer to the oracle target classifier. 
            </p>
        </td>
    </tr>
</table>

<br>
<hr>
<div style="text-align: center;">
    <h2>Highlights</h2>
</div>

<div style="text-align: center;">
    <h3>Deep Discriminative Target Clustering</h3>
</div>
	
<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		We propose to use deep discriminative target clustering in the output space and feature space at the same time. This is a new dual clustering framework. 
		The clustering algorithm obtains pseudo labels of target data to supervise the model training by minimizing an objective of two terms. 
		The first term is the KL divergence between the network prediction label distribution and the introduced auxiliary distribution; 
		the second term is a regularization of cluster size balance. 
		<br>
		<br>
		Here, category prediction probability modeling in feature space is based on Euclidean distance from instance to learnable cluster centers. 
		The clustering behavior in feature space can not only further reveal the inherent differences between target data, 
		but also act as the constraint of clustering in output space to maintain different cluster centers and avoid mode collapse.
            </p>
        </td>
    </tr>
</table>

<div style="text-align: center;">
    <h3>Structural Source Regularization</h3>
</div>
	
<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Based on the structural similarity between the source and target domains indicated by the UDA assumption, 
		we propose the structural source regularization â€” replacing the auxiliary distribution with truth label distribution, 
		and using the labeled source data to train the same classifier network layers, namely joint network training. 
		<br>
		<br>
		In addition, we propose a soft selection strategy for source samples, 
		which weights the source samples according to their importance to the target domain. 
		The concept of class-wise closeness in the assumption of structural domain similarity implies that 
		different source instances may have different regularization effects; 
		accordingly, they can be weighted based on distances to corresponding target clusters. 
            </p>
        </td>
    </tr>
</table>

<div style="text-align: center;">
    <h3>Training Algorithm</h3>
</div>
	

<div style="text-align: center;">
	<img src="resources/alg.png" width="500px">
</div>


<br>
<hr>
<div style="text-align: center;">
    <h2>Experiments</h2>
</div>

<div style="text-align: center;">
    <h3>Ablation Study and Learning Analysis</h3>
</div>

<table>
    <tr>
        <td>
            <p>
                <b>
                    R1: Ablation Study
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		In the following table, we can observe that when any one of our designed components is removed, the performance degrades, 
		verifying that (1) both feature discrimination and structural source regularization are effective for improving target clustering; 
		(2) the proposed soft source sample selection scheme leads to better regularization. 
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab1.png" width="700px">
            </div>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R2: Source Refinement
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                In the following figure, we can observe that the source images with a canonical viewpoint have the higher weights than those with top-down, bottom-up, and side viewpoints, 
		which is intuitive since all target images are shown only from a canonical viewpoint. 
		The observation affirms the rationality of our proposed soft source sample selection scheme.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/select.png" width="500px">
            </div>
	    <p style="text-align:center;">
		The images on the left are randomly sampled from the target domain Amazon and 
		those on the right are the top-ranked (the 3<sup>rd</sup> column) and bottom-ranked (the 4<sup>th</sup> column) samples from the source domain Webcam for three classes. 
		Note that the red numbers are the computed source weights. 
	    </p>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R3: Comparison under Inductive UDA Setting
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		In the following table, we can see that our proposed uncovering strategy SRDC achieves closer results to Oracle Model, 
		verifying the motivation of this work and the efficacy of our proposed SRDC.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab2.png" width="500px">
            </div>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R4: Feature Visualization
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                In the following figure, We can qualitatively observe that compared to Source Model, 
		the target domain features can be much better discriminated by SRDC, 
		which is based on data clustering to uncover the discriminative data structures.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tsne.png" width="900px">
            </div>
	    <p style="text-align:center;">
		The t-SNE visualization of embedded features on the target domain.
	    </p>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R5: Confusion Matrix
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                In the following figure,  we can observe quantitative improvements from Source Model to SRDC, further confirming the advantages of SRDC.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/confusion_matrix.png" width="900px">
            </div>
	    <p style="text-align:center;">
		The confusion matrix on the target domain.
	    </p>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R6: Convergence Performance
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                In the following figure, We can observe that SRDC enjoys faster and smoother convergence performance than Source Model.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/convergence.png" width="500px">
            </div>
        </td>
    </tr>
</table>


<br>
<div style="text-align: center;">
    <h3>Comparison with SOTA</h3>
</div>

<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		 Notably, with no explicit domain alignment, our proposed SRDC outperforms all existing methods on three UDA benchmark datasets.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab3.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Results (%) on Office-31 (ResNet-50).
	    </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab4.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Results (%) on ImageCLEF-DA (ResNet-50).
	    </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab5.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Results (%) on Office-Home (ResNet-50).
	    </p>
        </td>
    </tr>
</table>
	
This is the end of next edition!!! -->

<br>
<hr>

<div style="text-align: center;">
    <h2>BibTeX</h2>
</div>
      <pre>
  	<code>
      @article{tang2022unsupervised,
        title={Unsupervised domain adaptation via distilled discriminative clustering},
        author={Tang, Hui and Wang, Yaowei and Jia, Kui},
        journal={Pattern Recognition},
        volume={127},
        pages={108638},
        year={2022},
        publisher={Pergamon}
      }
  	</code>
      </pre>
	
<br>
<hr>

<div style="text-align: center;">
    <h2>Acknowledgements</h2>
</div>
      <p>
	      Based on a template by <a href="https://kyanchen.github.io/OvarNet/">Keyan Chen</a>.
      </p>

<br>
<br>
<br>

</body>
</html>
